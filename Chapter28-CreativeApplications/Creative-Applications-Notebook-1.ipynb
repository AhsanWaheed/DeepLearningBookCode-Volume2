{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "<small>\n",
    "Copyright (c) 2017 Andrew Glassner\n",
    "\n",
    "Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the \"Software\"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions:\n",
    "\n",
    "The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software.\n",
    "\n",
    "THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.\n",
    "</small>\n",
    "\n",
    "\n",
    "\n",
    "# Deep Learning From Basics to Practice\n",
    "## by Andrew Glassner, https://dlbasics.com, http://glassner.com\n",
    "------\n",
    "## Chapter 27: Applications\n",
    "### Notebook 1: Deep Dreams\n",
    "\n",
    "This notebook is provided as a “behind-the-scenes” look at code used to make some of the figures in this chapter. It is still in the hacked-together form used to develop the figures, and is only lightly commented."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### About this code:\n",
    "This notebook is adapted from\n",
    "https://github.com/giuseppebonaccorso/keras_deepdream\n",
    "by Giuseppe Bonaccorso.\n",
    "\n",
    "See License D in LICENSE.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras.backend as K_backend\n",
    "import multiprocessing\n",
    "import warnings\n",
    "\n",
    "from keras.applications.vgg19 import VGG19\n",
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.applications.resnet50 import ResNet50\n",
    "from keras.applications.xception import Xception\n",
    "from keras.applications.inception_v3 import InceptionV3\n",
    "from keras.applications.mobilenet import MobileNet\n",
    "from keras.applications.imagenet_utils import preprocess_input\n",
    "\n",
    "from scipy.optimize import minimize\n",
    "\n",
    "from skimage import img_as_float, img_as_ubyte\n",
    "from skimage.io import imread, imsave\n",
    "from skimage.transform import resize\n",
    "from skimage.transform import pyramid_gaussian, rescale\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "K_backend.set_image_data_format('channels_last')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Because this notebook will generally be left alone\n",
    "# for a long time, cranking out images, we won't use\n",
    "# our file_helper here to save the images, since that \n",
    "# requires that the images be displayed in the \n",
    "# notebook. Instead we use imread and imsave\n",
    "# from skimage.io. \n",
    "#\n",
    "# Make a File_Helper for saving and loading files.\n",
    "\n",
    "save_files = True\n",
    "\n",
    "import os, sys, inspect\n",
    "current_dir = os.path.dirname(os.path.abspath(inspect.getfile(inspect.currentframe())))\n",
    "sys.path.insert(0, os.path.dirname(current_dir)) # path to parent dir\n",
    "from DLBasics_Utilities import File_Helper\n",
    "file_helper = File_Helper(save_files)\n",
    "\n",
    "# get the input and output directories\n",
    "input_data_directory = file_helper.get_input_data_dir()\n",
    "output_data_directory = file_helper.get_saved_output_dir()\n",
    "\n",
    "# make sure the output directory exists\n",
    "already_existed = file_helper.check_for_directory(output_data_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Ignore some warnings from scikit-image\n",
    "warnings.simplefilter(\"ignore\")\n",
    "\n",
    "# Globals that get used when minimizing\n",
    "loss_tensor = None\n",
    "loss_gradient = None\n",
    "_loss_function = None\n",
    "_gradient_function = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def show_image(image):\n",
    "    fig, ax = plt.subplots(figsize=(18, 15))\n",
    "    ax.imshow(image)\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "    plt.show()\n",
    "    \n",
    "def preprocess_image(image):\n",
    "    return preprocess_input(np.expand_dims(image.astype(K_backend.floatx()), 0))\n",
    "    \n",
    "def postprocess_image(image):\n",
    "    image[:, :, :, 0] += 103.939\n",
    "    image[:, :, :, 1] += 116.779\n",
    "    image[:, :, :, 2] += 123.68\n",
    "    return np.clip(image[:, :, :, ::-1], 0, 255).astype('uint8')[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def build_pyramid_from_image(original_image_array):\n",
    "    # Create gaussian pyramid\n",
    "    original_image_as_float = img_as_float(original_image_array)\n",
    "    pyramid = list(pyramid_gaussian(original_image_as_float, downscale=2, max_layer=5))\n",
    "\n",
    "    # Convert each image to unsigned byte (0-255)\n",
    "    for i, image in enumerate(pyramid):\n",
    "        pyramid[i] = img_as_ubyte(pyramid[i])\n",
    "        print('Image {}) Size: {}'.format(i, pyramid[i].shape))\n",
    "    return pyramid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# We'll use a big hammer and just use all the activations on a given\n",
    "# layer with equal strength. It would be nice to apply per-filter weights\n",
    "# before adding them up.\n",
    "def make_loss_gradient_functions(convnet, chosen_layers, image_l2_weight):\n",
    "    global loss_tensor, loss_gradient, _loss_function, _gradient_function\n",
    "    \n",
    "    loss_tensor = 0.0\n",
    "\n",
    "    for layer, weight in chosen_layers.items():\n",
    "        loss_tensor += (-weight * K_backend.sum(K_backend.square(convnet.get_layer(layer).output)))\n",
    "\n",
    "    loss_tensor += image_l2_weight * K_backend.sum(K_backend.square(convnet.layers[0].input))\n",
    "\n",
    "    _loss_function = K_backend.function(inputs=[convnet.layers[0].input], outputs=[loss_tensor])\n",
    "\n",
    "    loss_gradient = K_backend.gradients(loss=loss_tensor, variables=[convnet.layers[0].input])\n",
    "    _gradient_function = K_backend.function(inputs=[convnet.layers[0].input], outputs=loss_gradient)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def loss(x, shape):\n",
    "    return _loss_function([x.reshape(shape)])[0]\n",
    "\n",
    "def gradient(x, shape):\n",
    "    return _gradient_function([x.reshape(shape)])[0].flatten().astype(np.float64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def process_image(image, iterations=2):\n",
    "    # Create bounds\n",
    "    bounds = np.ndarray(shape=(image.flatten().shape[0], 2))\n",
    "    bounds[:, 0] = -128.0\n",
    "    bounds[:, 1] = 128.0\n",
    "\n",
    "    # Initial value\n",
    "    x0 = image.flatten()\n",
    "\n",
    "    # Perform optimization\n",
    "    result = minimize(fun=loss, \n",
    "                      x0=x0, \n",
    "                      args=list(image.shape), \n",
    "                      jac=gradient, \n",
    "                      method='L-BFGS-B', \n",
    "                      bounds=bounds, \n",
    "                      options={'maxiter': iterations})\n",
    "    \n",
    "    return postprocess_image(np.copy(result.x.reshape(image.shape)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def build_dream(convnet, chosen_layers, image_l2_weight, original_image_array, do_resizing=False):\n",
    "\n",
    "    if do_resizing:\n",
    "        original_size = np.array(original_image_array).shape\n",
    "        original_image_array = resize(original_image_array, (299, 299))\n",
    "    pyramid = build_pyramid_from_image(original_image_array)\n",
    "\n",
    "    make_loss_gradient_functions(convnet, chosen_layers, image_l2_weight)\n",
    "    \n",
    "    processed_image = None\n",
    "\n",
    "    for i, image in enumerate(pyramid[::-1]):\n",
    "        print('Processing pyramid image: {} {}'.format(len(pyramid)-i, image.shape))\n",
    "\n",
    "        if processed_image is None:\n",
    "            processed_image = process_image(preprocess_image(image))\n",
    "        else:\n",
    "            h, w = image.shape[0:2]\n",
    "            ph, pw = processed_image.shape[0:2]\n",
    "            rescaled_image = rescale(processed_image, order=5, scale=(float(h)/float(ph), float(w)/float(pw)))\n",
    "            combined_image = img_as_ubyte((1.2*img_as_float(image) + 0.8*rescaled_image) / 2.0)\n",
    "            processed_image = process_image(preprocess_image(combined_image), iterations=5)\n",
    "            \n",
    "    if do_resizing:\n",
    "        processed_image = resize(processed_image, (original_size[0], original_size[1]))\n",
    "    return processed_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create visualization of the layers in VGG16\n",
    "def visualize_layers():\n",
    "    \n",
    "    convnet = VGG16(include_top=False, weights='imagenet')\n",
    "    np.random.seed(42)\n",
    "    \n",
    "    layer_names = [\n",
    "        'block1_conv1', 'block1_conv2',\n",
    "        'block2_conv1', 'block2_conv2',\n",
    "        'block3_conv1', 'block3_conv2', 'block3_conv3',\n",
    "        'block4_conv1', 'block4_conv2', 'block4_conv3',\n",
    "        'block5_conv1', 'block5_conv2', 'block5_conv3',\n",
    "    ]\n",
    "    \n",
    "    for name in layer_names:    \n",
    "        original_image_array = np.random.uniform(low=-1, high=1, size=(224, 224, 3))\n",
    "        layers_and_weights = { name : 0.001}\n",
    "        original_image_l2_weight = 0\n",
    "        do_resizing = False\n",
    "        dream_image = build_dream(convnet, layers_and_weights, original_image_l2_weight,\n",
    "                                  original_image_array, do_resizing)\n",
    "        output_name = output_data_directory+'/only-layer-'+name+'.png'        \n",
    "        imsave(output_name, dream_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "visualize_layers()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def stochastic_space_search_vgg_models(number_of_images_to_make=10000, random_seed=42):\n",
    "    '''Generate random sets of variables and make deep-dream images.\n",
    "    Generally, set number_of_images_to_make to some huge number, like 10000, and\n",
    "    then leave the program running overnight (or for a weekend!). Then stop it\n",
    "    manually when you have enough results.\n",
    "      If you do leave this running for a long time, it might be worth the effort of\n",
    "    adding a dictionary to keep track of which sets of parameters have been tried,\n",
    "    so we don't accidentally repeat. \n",
    "      The variations are:\n",
    "    * choice of image to start with\n",
    "    * choice of network (VGG16 or VGG19 right now)\n",
    "    * whether or not to scale image down to 299x299 for processing\n",
    "    * the weight for the original image's L2 norm, when added into the loss\n",
    "    * weights on the last 3 (or 4, if VGG19) convolution layers of the network\n",
    "    '''\n",
    "    image_list = [\n",
    "        'waters-3038803_1280-crop', # frog\n",
    "        'cat-2184682_1280',         # cat\n",
    "        'dog-1210559_1280',         # dog\n",
    "    ]\n",
    "\n",
    "    print(\"loading convnets\")\n",
    "    x = imread('input_data/waters-3038803_1280-crop.jpg')\n",
    "    print(\"x.shape=\",x.shape)\n",
    "    x0 = K_backend.zeros([1, x.shape[0], x.shape[1], x.shape[2]])\n",
    "    convnet_dict = {\n",
    "        'vgg16': VGG16(include_top=False, weights='imagenet'),\n",
    "        'vgg19': VGG19(include_top=False, weights='imagenet'),\n",
    "        #'resnet50': ResNet50(include_top=False, weights='imagenet'),\n",
    "        #'xception': Xception(include_top=False, weights='imagenet'),\n",
    "        #'inceptionv3': InceptionV3(include_top=False, weights='imagenet', input_tensor=x0),\n",
    "        }\n",
    "    print(\"done, all loaded.\")\n",
    "        \n",
    "    np.random.seed(random_seed)\n",
    "    \n",
    "    for i in range(number_of_images_to_make):\n",
    "        image_num = np.random.choice([0, 1, 2])\n",
    "        convnet_size = np.random.choice([16, 19])\n",
    "        convnet_name = 'vgg'+str(convnet_size)\n",
    "        do_resizing = np.random.uniform() > 0.5    \n",
    "        # These values are from trial and error. Feel free to change them.\n",
    "        original_image_l2_weight = np.random.choice([0.001, 0.005, 0.00005]) \n",
    "        # w1 through w4 are the weights applied to the convolution layers\n",
    "        # (the names match the layer names: _conv1, _conv2, etc.)\n",
    "        w1 = np.random.choice([0, 1, 2, 5])\n",
    "        w2 = np.random.choice([0, 1, 2, 5])\n",
    "        w3 = np.random.choice([0, 1, 2, 5])\n",
    "        w4 = np.random.choice([0, 1, 2, 5])\n",
    "        if w1+w2+w3+w4 == 0:\n",
    "            continue\n",
    "        print(\"-------- New set of dream parameters -----\")\n",
    "        print(\"image_num=\",image_num,\" name=\",image_list[image_num])\n",
    "        print(\"convnet_size=\",convnet_size,\" convnet_name=\",convnet_name)\n",
    "        print(\"do_resizing=\",do_resizing, \"original_image_l2_weight=\",original_image_l2_weight)\n",
    "        print(\"w1=\",w1,\" w2=\",w2,\" w3=\",w3,\" w4=\",w4)\n",
    "        print(\"--------\")\n",
    "        image_name = image_list[image_num]    \n",
    "        convnet = convnet_dict[convnet_name]\n",
    "        original_image = input_data_directory+'/'+image_name+'.jpg'\n",
    "        original_image_array = imread(original_image)\n",
    "\n",
    "        layer_set = {'layer_dict':{}, 'l2_weight': original_image_l2_weight }\n",
    "        if w1 != 0:\n",
    "            layer_set['layer_dict']['block5_conv1'] = w1 * 0.001\n",
    "        if w2 != 0:\n",
    "            layer_set['layer_dict']['block5_conv2'] = w2 * 0.001\n",
    "        if w3 != 0:\n",
    "            layer_set['layer_dict']['block5_conv3'] = w3 * 0.001\n",
    "        if (convnet_size==19) and (w4 != 0):\n",
    "            layer_set['layer_dict']['block5_conv4'] = w4 * 0.001\n",
    "        layers_and_weights = layer_set['layer_dict']\n",
    "        \n",
    "\n",
    "\n",
    "        dream_image = build_dream(convnet, layers_and_weights, original_image_l2_weight,\n",
    "                                  original_image_array, do_resizing)\n",
    "\n",
    "        output_name = output_data_directory+'/Dream-'+convnet_name\n",
    "        output_name += '-wgts-'+str(w1)+'_'+str(w2)+'_'+str(w3)+'_'+str(w4)\n",
    "        output_name += '-image_l2_weight-'+str(original_image_l2_weight)\n",
    "        output_name += '-resize-'+str(do_resizing)+'-'+image_name+'.png'\n",
    "        \n",
    "        imsave(output_name, dream_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "stochastic_space_search_vgg_models()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
